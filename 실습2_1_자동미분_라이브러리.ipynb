{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoonjihwan402/medical-data/blob/main/%EC%8B%A4%EC%8A%B52_1_%EC%9E%90%EB%8F%99%EB%AF%B8%EB%B6%84_%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25533d3b",
      "metadata": {
        "id": "25533d3b"
      },
      "source": [
        "# 실습 3: 자동미분(AutoDiff) 라이브러리"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f60968f6",
      "metadata": {
        "id": "f60968f6"
      },
      "source": [
        "앞서 우리는 그래디언트 기반 학습에 대해 살펴보았다. $\\mathscr{L}$이 간단한 함수일 때는 편미분하는 것이 간단한 일이었지만, 앞으로는 손으로 편미분을 계산하기는 어려운 다양한 함수들을 $\\mathscr{L}$ 로 만나게 될 것이다. 이럴 때 필요한 것이 바로 컴퓨터의 계산 능력이다. 그래디언트 기반 학습에 대한 관심이 크게 증가하면서, 미분을 자동으로 계산해주는 자동미분 라이브러리가 여럿 개발되었다. 널리 쓰이는 라이브러리로는 [PyTorch](https://pytorch.org/), [TensorFlow](https://www.tensorflow.org/), [JAX](https://github.com/google/jax), [Zygote](https://github.com/FluxML/Zygote.jl) 등이 있다.\n",
        "\n",
        "이 책에서는 위의 라이브러리 중에서 쉽게 이해하고 사용할 수 있는 PyTorch 라이브러리를 사용할 것이다. 이 라이브러리는 NumPy 라이브러리와 매우 유사하게 동작하기 때문에, NumPy만 잘 알아도 쉽게 사용할 수 있다. NumPy에서 ndarray(배열)가 기본이 되는 핵심 객체인 것과 같이, PyTorch의 핵심 객체는 Tensor(텐서)라고 부른다. 이 Tensor는 ndarray와 매우 유사하게 동작이 가능하다.\n",
        "\n",
        "이 실습에서 PyTorch를 통한 자동미분에 익숙해지고 나면, 이 책 전반에 걸쳐 PyTorch를 자유자재로 사용하며 딥러닝을 배우게 될 것이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e93acc4d",
      "metadata": {
        "id": "e93acc4d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch as tc\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03d35d08",
      "metadata": {
        "id": "03d35d08"
      },
      "source": [
        "구글 코랩(Google Colab)에서는 PyTorch가 기본적으로 설치되어 있다. 따라서 별도로 설치할 필요 없이 바로 사용 가능하다. PyTorch가 제대로 설치되어 있는지 확인하려면 아래와 같은 코드를 실행해볼 수 있다.\n",
        "torch.cuda.is_available() 코드가 False의 결과가 나오면 메뉴에서\n",
        "\n",
        "런타임 > 런타임 유형 변경 > 하드웨어 가속기\n",
        "\n",
        "에서 보면 CPU가 선택되어 있을 것인데 이를 GPU로 바꿔줘야 한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "kPxSBddWT2OT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPxSBddWT2OT",
        "outputId": "c04d506b-6247-4383-9b94-d56721469b5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a73926ed",
      "metadata": {
        "id": "a73926ed"
      },
      "source": [
        "### Step 1. PyTorch의 여러가지 함수"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "335815d5",
      "metadata": {
        "id": "335815d5"
      },
      "source": [
        "라이브러리를 사용할 때, 유명한 라이브러리의 경우에는 구글링을 통해 쉽게 설명된 블로그 등을 참고할 수도 있다. 하지만 정석은 라이브러리 개발자가 작성한 도큐먼트(document)를 읽는 것이다. 이 실습에서는 PyTorch를 사용한 자동미분을 배우는 것을 가장 중요한 목적으로 다루고 있으므로, 더 다양한 함수와 기능이 궁금하다면 직접 [도큐먼트](https://mygrad.readthedocs.io/en/latest/)를 읽어보길 바란다. 또한, NumPy의 기본 함수들과 일치하는 함수를 많이 가지고 있으므로, NumPy의 함수들을 찾아 PyTorch에 적용해보아도 좋다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d06b0a0d",
      "metadata": {
        "id": "d06b0a0d"
      },
      "source": [
        "#### Tensor 생성\n",
        "Tensor는 Pytorch 라이브러리에서 사용하는 데이터를 배열 형식으로 저장하도록 한다. 다양한 방식으로 Tensor를 생성할 수 있다. 다음은 Tensor를 생성하는 여러 가지 예이다. tc.tensor 외에도 Tensor를 생성하는 다양한 함수들이 있다. 직접 코드를 실행하여 output을 확인해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42d2424d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42d2424d",
        "outputId": "4e4d9ba9-41dd-467c-f6ee-11c2874cab83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3000)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# 단일 숫자로 생성한 Tensor\n",
        "tc.tensor(2.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b71a705",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b71a705",
        "outputId": "3014e0cc-a640-40d8-b4fd-e21a0865763b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# 시퀀스(리스트, 튜플 등) 자료형으로 생성한 Tensor.\n",
        "# dtype을 지정할 수 있는 모든 함수에서\n",
        "# 32-bit floats를 저장하는 텐서를 반환하도록 지정 가능.\n",
        "tc.tensor([1.0,2.0,3.0], dtype=tc.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "737f62f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "737f62f3",
        "outputId": "54740a71-5338-4dd7-8e54-4f35df76be67"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# numpy.ndarray로부터 생성한 Tensor\n",
        "arr = np.ones((3,3))\n",
        "tc.tensor(arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "970b3585",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "970b3585",
        "outputId": "b3351e6c-4230-485a-feca-8ea920ee27aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Tensor 생성 함수 (ones, zeros; 각각 1, 0으로 채움)\n",
        "tc.zeros(2, 3, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbe81f6c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbe81f6c",
        "outputId": "7e7928e5-c843-427b-cbb5-67595d262ad1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-5, -3, -1,  1,  3,  5,  7,  9, 11, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Tensor 생성 함수 (start 부터 stop 까지 step 만큼 띄워가며 채움)\n",
        "tc.arange(-5, 15, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae113b63",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae113b63",
        "outputId": "8ade1406-e691-4bdb-f6e5-3a6df9802d7e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8.])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# start = 0, step = 1이 default 값\n",
        "tc.arange(9.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbdb971e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbdb971e",
        "outputId": "741496c6-c572-46f0-e027-ee01ecfd1617"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7583, 0.7637, 0.7722, 0.6775],\n",
              "        [0.7398, 0.4782, 0.0479, 0.1466],\n",
              "        [0.5031, 0.5559, 0.7432, 0.1013]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# 0~1 사이의 값 무작위로 리턴 (확률분포는 균등분포(uniform))\n",
        "tc.rand(3,4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9373be2a",
      "metadata": {
        "id": "9373be2a"
      },
      "source": [
        "<문제: 주어진 조건을 만족하는 Tensor 생성하기>\n",
        "\n",
        "구간 $[0, \\pi]$에 등간격으로 분포한 15개의 구성요소로 이루어진 shape-(15,)인 tensor를 만들어보자. (Hint: tc.linspace(), tc.pi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82ebd43d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82ebd43d",
        "outputId": "c0f91dab-8644-4ff5-fe4b-00201f282279",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.2244, 0.4488, 0.6732, 0.8976, 1.1220, 1.3464, 1.5708, 1.7952,\n",
              "        2.0196, 2.2440, 2.4684, 2.6928, 2.9172, 3.1416])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# 여기에 코드 작성\n",
        "tc.linspace(0,tc.pi,15)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71697cae",
      "metadata": {
        "id": "71697cae"
      },
      "source": [
        "#### Tensor 변형\n",
        "Tensor의 모양을 변형하는 함수들도 있다. 직접 코드를 실행하여 output을 확인해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38946f50",
      "metadata": {
        "id": "38946f50",
        "outputId": "b78017db-91e3-46bb-9e74-4c3d1e528f99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 2.],\n",
              "        [3., 4., 5.],\n",
              "        [6., 7., 8.]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Tensor의 행과 열을 바꾸어주는 함수\n",
        "x = tc.arange(9.) #Tensor([0., 1., 2., 3., 4., 5., 6., 7., 8.])\n",
        "x.reshape(3, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a22b453",
      "metadata": {
        "id": "3a22b453",
        "outputId": "ac89c1e9-452a-4c75-e032-c0d921b87ecb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  3,  6,  9],\n",
              "        [ 1,  4,  7, 10],\n",
              "        [ 2,  5,  8, 11]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Tensor의 전치 행렬을 구하는 함수\n",
        "x = tc.tensor([[0,1,2],[3,4,5],[6,7,8],[9,10,11]])\n",
        "x.t()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a38b3441",
      "metadata": {
        "id": "a38b3441",
        "outputId": "2bd18d73-0ab5-475f-d3a4-db27ec82e8cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# 슬라이싱 (자유자재로 쓸 수 있으면 좋다)\n",
        "x = tc.tensor([[1,2,3,4,5],[6,7,8,9,10]])\n",
        "x[0, 2:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6320c0ee",
      "metadata": {
        "id": "6320c0ee",
        "outputId": "53eec44b-c0e0-4f3a-a995-61f32762e53c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "x = tc.tensor([[1,2,3,4,5],[6,7,8,9,10]])\n",
        "x[0, -3:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6232d6c1",
      "metadata": {
        "id": "6232d6c1"
      },
      "source": [
        "#### Tensor 표준 수학 연산\n",
        "\n",
        "먼저, PyTorch에서 제공하는 표준적인 수학 함수들을 알아보자. 기본적인 산술 연산을 하는 함수를 비롯하여, (sum, mean, var, std, max, min) 등의 통계량을 구하는 함수 등이 제공된다. 또한, 삼각함수, 쌍곡함수, 지수함수, 로그함수 등의 초월함수도 제공된다. NumPy의 함수들과 동일하게, 벡터화된 함수들이다.\n",
        "\n",
        "단항 함수는 텐서에 대해 요소별로 각각 작동한다. 이항 함수는 두 텐서에 대해 대응되는 위치의 요소 간에 자연스럽게 작동한다. 두 텐서가 동일한 모양이 아니더라도 Numpy와 같은 [브로드캐스팅(Broadcasting)](https://numpy.org/doc/stable/user/basics.broadcasting.html) 규칙을 따르기 때문에, 이항 함수가 작동할 수 있는 경우가 있다.\n",
        "\n",
        "직접 코드를 실행하여 output을 확인해보자. 이를 통해 단항 연산과 이항 연산을 다루는 여러 함수에 대해 이해해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4d930c8",
      "metadata": {
        "id": "b4d930c8"
      },
      "outputs": [],
      "source": [
        "x = tc.tensor([0.0, 0.25, 0.5, 0.75, 1.0])\n",
        "y = tc.tensor([[0.],[1.],[2.]])\n",
        "z = tc.tensor([[0,1,2,3],[4,5,6,7],[8,9,10,11]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa53ba6b",
      "metadata": {
        "id": "aa53ba6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63321fa4-8175-4dea-87cb-e7074b876373"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.2474, 0.4794, 0.6816, 0.8415])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# 단항 함수 중 하나인 삼각함수 sin()\n",
        "# 텐서의 모든 요소의 sin 값으로 채워진 같은 크기의 텐서\n",
        "tc.sin(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27891022",
      "metadata": {
        "id": "27891022",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "125ab7c6-2fb1-42b5-9d7d-5b456da7436a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(66)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# 단항 함수 중 통계량을 구하는 함수들은 axis 인자를 가짐\n",
        "# axis가 0이면 행에 대해서만 함수를 적용하고,\n",
        "# axis가 1이면 열에 대해서만 함수를 적용\n",
        "tc.sum(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99ed2ce2",
      "metadata": {
        "id": "99ed2ce2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0d58379-9b32-4bbf-e6aa-6cfa8a8f1f6d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([12, 15, 18, 21])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "tc.sum(z, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "628e8b1b",
      "metadata": {
        "id": "628e8b1b"
      },
      "source": [
        "z = tc.tensor([[0,1,2,3],[4,5,6,7],[8,9,10,11]])\n",
        "\n",
        "=>\n",
        "\n",
        "$[[0,1,2,3], \\\\\n",
        "    [4,5,6,7], \\\\\n",
        "    [8,9,10,11]]$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fe0294b",
      "metadata": {
        "id": "9fe0294b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d97c6c6c-62be-40bb-a692-981b854add07"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 6, 22, 38])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "tc.sum(z, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9686434",
      "metadata": {
        "id": "b9686434",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fab2403-5aac-4a78-dec8-7099b70057dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.2500, 0.5000, 0.7500, 1.0000],\n",
              "        [1.0000, 1.2500, 1.5000, 1.7500, 2.0000],\n",
              "        [2.0000, 2.2500, 2.5000, 2.7500, 3.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# 브로드캐스팅 예(1)\n",
        "# x+y, y+z는 브로드캐스팅이 가능, x+z는 불가능\n",
        "x+y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c0e5310",
      "metadata": {
        "id": "6c0e5310",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db501ca6-9d8a-447a-b346-86ffd68669af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  2.,  3.],\n",
              "        [ 5.,  6.,  7.,  8.],\n",
              "        [10., 11., 12., 13.]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "y+z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef7e7090",
      "metadata": {
        "id": "ef7e7090",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "cf3dff25-cc6e-4b9a-8077-c782c7d67e49"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (5) must match the size of tensor b (4) at non-singleton dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-26-1565744572.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mz\u001b[0m \u001b[0;31m# Error 발생\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (4) at non-singleton dimension 1"
          ]
        }
      ],
      "source": [
        "x+z # Error 발생"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "942ebf93",
      "metadata": {
        "id": "942ebf93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c45245e-ae32-4f4e-c328-108bd89d3246"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.2500, 0.5000, 0.7500, 1.0000],\n",
              "        [0.0000, 0.5000, 1.0000, 1.5000, 2.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# 브로드캐스팅 예(2)\n",
        "# x*y, y*z는 브로드캐스팅이 가능, x*z는 불가능\n",
        "x*y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45b61b7f",
      "metadata": {
        "id": "45b61b7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2623235-9d96-44cc-9127-92b9916c2a89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  0.,  0.,  0.],\n",
              "        [ 4.,  5.,  6.,  7.],\n",
              "        [16., 18., 20., 22.]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "y*z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b613e37",
      "metadata": {
        "id": "6b613e37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "8696b721-ddbb-44d0-8b31-961541874403"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (5) must match the size of tensor b (4) at non-singleton dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-29-262476392.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mz\u001b[0m \u001b[0;31m# Error 발생\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (4) at non-singleton dimension 1"
          ]
        }
      ],
      "source": [
        "x*z # Error 발생"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad45aec1",
      "metadata": {
        "id": "ad45aec1"
      },
      "source": [
        "<문제: Pytorch의 기본 수학 연산>\n",
        "\n",
        "아래와 같이 정의된 텐서 x에 대해 여러 가지 수학 연산을 적용하여 여러 가지 텐서를 구해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a98929d0",
      "metadata": {
        "id": "a98929d0"
      },
      "outputs": [],
      "source": [
        "x = tc.Tensor([[ 0.,  1.,  2.,  3.],\n",
        "...                [ 4.,  5.,  6.,  7.],\n",
        "...                [ 8.,  9., 10., 11.],\n",
        "...                [12., 13., 14., 15.]])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1번 문제"
      ],
      "metadata": {
        "id": "prqrJypdiwJ2"
      },
      "id": "prqrJypdiwJ2"
    },
    {
      "cell_type": "markdown",
      "id": "6e03887e",
      "metadata": {
        "id": "6e03887e"
      },
      "source": [
        "1. x의 3행의 첫번째, 세번째 원소에 대한 자연로그 값으로 채워진 shape-(2,)인 Tensor를 구해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b89e057",
      "metadata": {
        "id": "7b89e057",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50be2b65-bc1f-44ad-f691-0302dfee5091"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.0794, 2.3026])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "tc.log(x[2,0::2])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d1e928f",
      "metadata": {
        "id": "3d1e928f"
      },
      "source": [
        "## 1번 문제 정답"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tc.log(x[2,0::2])"
      ],
      "metadata": {
        "id": "2wSGga_FiWIq"
      },
      "id": "2wSGga_FiWIq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1번 문제 출력 결과 : tensor([2.0794, 2.3026])"
      ],
      "metadata": {
        "id": "F7fzgO9kikUX"
      },
      "id": "F7fzgO9kikUX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2번 문제"
      ],
      "metadata": {
        "id": "6M3xaJomisFT"
      },
      "id": "6M3xaJomisFT"
    },
    {
      "cell_type": "markdown",
      "id": "65c19bdd",
      "metadata": {
        "id": "65c19bdd"
      },
      "source": [
        "2. x를 가로, 세로로 4등분한 각 귀퉁이(왼쪽 위, 오른쪽 위, 왼쪽 아래, 오른쪽 아래)의 4개 원소를 더하여 shape-(2,2)인 Tensor를 구해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0076def",
      "metadata": {
        "id": "b0076def",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82093606-e7ff-476a-da9a-6057ab36a939"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[20., 24.],\n",
              "        [36., 40.]])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "x[:2,:2] + x[:2,2:] + x[2:,:2] + x[2:,2:]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2번 문제 정답"
      ],
      "metadata": {
        "id": "AyY6znLKidQj"
      },
      "id": "AyY6znLKidQj"
    },
    {
      "cell_type": "code",
      "source": [
        "x[:2,:2] + x[:2,2:] + x[2:,:2] + x[2:,2:]"
      ],
      "metadata": {
        "id": "a3JavlrAi3Nn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67534b38-d23d-4362-93aa-5c3343d9e921"
      },
      "id": "a3JavlrAi3Nn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[20., 24.],\n",
              "        [36., 40.]])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2번 문제 출력 결과 :\n",
        "\n",
        "tensor([[20., 24.],\\\n",
        "        [36., 40.]])"
      ],
      "metadata": {
        "id": "2ZYKqDfmjKFu"
      },
      "id": "2ZYKqDfmjKFu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3번 문제"
      ],
      "metadata": {
        "id": "t8AcEm9Ni-9i"
      },
      "id": "t8AcEm9Ni-9i"
    },
    {
      "cell_type": "markdown",
      "id": "d18ec6e0",
      "metadata": {
        "id": "d18ec6e0"
      },
      "source": [
        "  3. x의 각 열의 평균을 구하여 shape-(4,)인 Tensor를 구해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ff6a6bc",
      "metadata": {
        "id": "5ff6a6bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "729a8848-d8a7-4fbd-ac13-47fadc77d66b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6., 7., 8., 9.])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "# 여기에 코드 작성\n",
        "x.mean(axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3번 문제 정답"
      ],
      "metadata": {
        "id": "Mf_Q1BkEjoCf"
      },
      "id": "Mf_Q1BkEjoCf"
    },
    {
      "cell_type": "code",
      "source": [
        "x.mean(axis=0)"
      ],
      "metadata": {
        "id": "-pmoGU-0jnk5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8bc97b4-f7a4-4b8a-a22f-564539367353"
      },
      "id": "-pmoGU-0jnk5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6., 7., 8., 9.])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3번 문제 출력 결과 : tensor([6., 7., 8., 9.])"
      ],
      "metadata": {
        "id": "Pn-E0xyKjobv"
      },
      "id": "Pn-E0xyKjobv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4번 문제"
      ],
      "metadata": {
        "id": "W7y-HGgwjzr7"
      },
      "id": "W7y-HGgwjzr7"
    },
    {
      "cell_type": "markdown",
      "id": "d29b6965",
      "metadata": {
        "id": "d29b6965"
      },
      "source": [
        "4. x의 각 행을 벡터로보고, 각 벡터가 크기가 1이 되도록 정규화하여 shape-(4,4)\n",
        "\n",
        "1.   항목 추가\n",
        "2.   항목 추가\n",
        "\n",
        "인 Tensor로 업데이트해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57234e34",
      "metadata": {
        "id": "57234e34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac96dc33-53cc-4fd4-f9fc-6c587054d6ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.2673, 0.5345, 0.8018],\n",
              "        [0.3563, 0.4454, 0.5345, 0.6236],\n",
              "        [0.4182, 0.4704, 0.5227, 0.5750],\n",
              "        [0.4429, 0.4798, 0.5167, 0.5537]])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "# 여기에 코드 작성\n",
        "x /= tc.sqrt(tc.sum(x**2,axis=1,keepdims = True))\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d038eb54",
      "metadata": {
        "id": "d038eb54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "045a447a-eeff-4f46-ce87-e9caa133d64e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000, 1.0000, 1.0000, 1.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "# 정규화가 잘 되었는지 확인하기\n",
        "(x**2).sum(axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4번 문제 정답"
      ],
      "metadata": {
        "id": "-zPuP1PPj_yj"
      },
      "id": "-zPuP1PPj_yj"
    },
    {
      "cell_type": "code",
      "source": [
        "x /= tc.sqrt(tc.sum(x**2,axis=1,keepdims = True))\n",
        "x"
      ],
      "metadata": {
        "id": "hZ_679jyj3rQ"
      },
      "id": "hZ_679jyj3rQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4번 문제 출력 결과 : \\\\\n",
        "\n",
        "tensor([[0.0000, 0.2673, 0.5345, 0.8018], \\\n",
        "        [0.3563, 0.4454, 0.5345, 0.6236], \\\n",
        "        [0.4182, 0.4704, 0.5227, 0.5750], \\\n",
        "        [0.4429, 0.4798, 0.5167, 0.5537]])"
      ],
      "metadata": {
        "id": "dVP8WS0PkDKT"
      },
      "id": "dVP8WS0PkDKT"
    },
    {
      "cell_type": "code",
      "source": [
        "# 정규화가 잘 되었는지 확인하기 정답\n",
        "(x**2).sum(axis=1)"
      ],
      "metadata": {
        "id": "J9xPBjRsj3ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f8b37b5-ef05-41b5-a757-0973f6304dfa"
      },
      "id": "J9xPBjRsj3ff",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000, 1.0000, 1.0000, 1.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#   "
      ],
      "metadata": {
        "id": "n8GyohNmkccZ"
      },
      "id": "n8GyohNmkccZ"
    },
    {
      "cell_type": "markdown",
      "id": "ca7b8e69",
      "metadata": {
        "id": "ca7b8e69"
      },
      "source": [
        "#### 선형대수 연산 함수"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47ce788e",
      "metadata": {
        "id": "47ce788e"
      },
      "source": [
        "PyTorch에는 선형대수 연산을 쉽게 계산하도록 도와주는 함수들도 있다. matmul()은 행렬곱을 계산해주는 함수이다. 이를 이용하여 벡터의 점곱(스칼라곱)을 계산할 수도 있다. einsum()은 아인슈타인 표기법(Einstein notation 또는 Einstein summation convention)을 계산하는 함수이다. 이는 다소 복잡한 함수이지만, 다양한 사용자 지정 가능한 선형 대수 연산을 수행할 수 있다. PyTorch가 자동미분을 수행할 때 이 연산들을 통해 수행한다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "171b9c09",
      "metadata": {
        "id": "171b9c09"
      },
      "source": [
        "먼저 이항 연산 함수인 matmul()연산은 행렬곱을 기본으로 하는 함수이므로 2차원 텐서 간의 연산이 가장 자연스럽게 정의된다. 1차원 텐서 간의 matmul()을 명령하면 1차원 텐서를 1xn 크기의 2차원 텐서로 생각하여 연산을 진행한다. 그리고 n차원(3차원 이상)의 텐서 간의 matmul()은 n-2차원의 텐서의 구성요소가 2차원 텐서(행렬)인 것으로 생각하여 연산을 진행한다. 즉, 행렬이 여러개 모여있는 것으로 생각하고 행렬곱을 진행하는 것이다. matmul()연산 또한 NumPy의 브로드캐스팅 규칙을 따르는 함수이기 때문에 3차원 이상의 텐서에 대해서는 브로드캐스팅에도 유의해야 한다.\n",
        "\n",
        "matmul()을 사용할 때는 tc.matmul(x,y)로 사용할 수 있지만, x @ y 와 같이 연산자 @를 이용하여도 같은 연산을 할 수 있도록 정의되어 있다. 아래의 사용 예시를 따라가면 matmul() 함수의 사용법을 이해할 수 있을 것이다. 직접 코드를 실행하여 output을 확인해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0d89dcb",
      "metadata": {
        "id": "c0d89dcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a3a3438-6722-4a88-daaf-28050366dc9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-11.)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# 1차원 텐서의 matmul 연산은 점곱(스칼라곱)을 구하는 것과 같음\n",
        "x = tc.tensor([1.0, 2.0])\n",
        "y = tc.tensor([-3.0, -4.0])\n",
        "tc.matmul(x,y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1차원 텐서의 matmul 연산은 점곱(스칼라곱)을 구하는 것과 같음 / 벡터 내\n",
        "x = tc.tensor([1.0, 2.0])\n",
        "y = tc.tensor([-3.0, -4.0])\n",
        "x @ y"
      ],
      "metadata": {
        "id": "oKmJhLeklBTI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d8c9cc3-75d3-4af4-9a59-8380e206a332"
      },
      "id": "oKmJhLeklBTI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-11.)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "594d0ad6",
      "metadata": {
        "id": "594d0ad6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2336022-ecd0-4c26-da83-31563436945b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 4,  1,  5],\n",
              "        [ 2,  2,  6],\n",
              "        [10,  4, 16],\n",
              "        [20, 11, 39]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# 2차원 텐서의 matmul 연산은 그냥 행렬곱과 같음 / 행렬 곱\n",
        "a = tc.tensor([[1, 0], [0, 1], [2, 1], [3, 4]])\n",
        "b = tc.tensor([[4, 1, 5], [2, 2, 6]])\n",
        "tc.matmul(a, b) # a @ b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "375463a3",
      "metadata": {
        "id": "375463a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b4df09c-593f-4a97-b34d-443e99da9270"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0,  1,  2],\n",
            "         [ 3,  4,  5]],\n",
            "\n",
            "        [[ 2,  3,  4],\n",
            "         [ 5,  6,  7]],\n",
            "\n",
            "        [[ 4,  5,  6],\n",
            "         [ 7,  8,  9]],\n",
            "\n",
            "        [[ 6,  7,  8],\n",
            "         [ 9, 10, 11]]])\n",
            "tensor([[[ 0,  1,  2],\n",
            "         [ 3,  4,  5],\n",
            "         [ 6,  7,  8]],\n",
            "\n",
            "        [[ 2,  3,  4],\n",
            "         [ 5,  6,  7],\n",
            "         [ 8,  9, 10]],\n",
            "\n",
            "        [[ 4,  5,  6],\n",
            "         [ 7,  8,  9],\n",
            "         [10, 11, 12]],\n",
            "\n",
            "        [[ 6,  7,  8],\n",
            "         [ 9, 10, 11],\n",
            "         [12, 13, 14]]])\n",
            "tensor([[[ 15,  18,  21],\n",
            "         [ 42,  54,  66]],\n",
            "\n",
            "        [[ 51,  60,  69],\n",
            "         [ 96, 114, 132]],\n",
            "\n",
            "        [[111, 126, 141],\n",
            "         [174, 198, 222]],\n",
            "\n",
            "        [[195, 216, 237],\n",
            "         [276, 306, 336]]])\n"
          ]
        }
      ],
      "source": [
        "# A는 크기가 (4, 2, 3)인 3차원 텐서\n",
        "A1 = tc.arange(2*3).reshape((2,3))\n",
        "A = tc.stack([A1, A1+2, A1+4, A1+6])\n",
        "\n",
        "# B는 크기가 (4, 3, 3)인 3차원 텐서\n",
        "B1 = tc.arange(3*3).reshape((3,3))\n",
        "B = tc.stack([B1, B1+2,B1+4, B1+6])\n",
        "\n",
        "# matmul 연산을 제대로 이해했는지 확인하기 위해\n",
        "# 손으로도 직접 계산해보고, 결과가 동일한지 확인해보기\n",
        "print(A)\n",
        "print(B)\n",
        "print(tc.matmul(A, B))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6479f8f0",
      "metadata": {
        "id": "6479f8f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dfec5a0-7820-4ce2-8c11-079e88556e75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 2, 3])\n",
            "tensor([[[ 15,  18,  21],\n",
            "         [ 42,  54,  66]],\n",
            "\n",
            "        [[ 51,  60,  69],\n",
            "         [ 96, 114, 132]],\n",
            "\n",
            "        [[111, 126, 141],\n",
            "         [174, 198, 222]],\n",
            "\n",
            "        [[195, 216, 237],\n",
            "         [276, 306, 336]]])\n"
          ]
        }
      ],
      "source": [
        "C = tc.matmul(A, B)\n",
        "print(C.shape)\n",
        "print(C)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4b01755",
      "metadata": {
        "id": "e4b01755",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b9cb717-b047-4b66-b3ff-eca719664907"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.4666, 0.4910],\n",
              "         [0.7770, 0.3529],\n",
              "         [0.5988, 0.6875]],\n",
              "\n",
              "        [[0.2831, 0.6187],\n",
              "         [0.4890, 0.6780],\n",
              "         [0.4781, 0.3966]],\n",
              "\n",
              "        [[0.6543, 0.3213],\n",
              "         [0.7732, 0.5047],\n",
              "         [0.3240, 0.6988]],\n",
              "\n",
              "        [[0.2258, 0.1771],\n",
              "         [0.3243, 0.5147],\n",
              "         [0.3674, 0.2765]],\n",
              "\n",
              "        [[0.5348, 0.5470],\n",
              "         [0.2040, 0.2055],\n",
              "         [0.2017, 0.2803]]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# 브로드캐스팅 예 (y를 5개로 브로드캐스팅하여 x와 연산)\n",
        "x = tc.rand(5, 3, 4)\n",
        "y = tc.rand(4,2)\n",
        "tc.matmul(x, y) # x @ y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bb78257",
      "metadata": {
        "id": "7bb78257"
      },
      "source": [
        "NumPy에서는 행렬곱 연산을 하는 함수가 두 개 있다. 바로 dot연산과 matmul 연산이다.두 함수는 2차원 배열 두개의 곱에 대해 동일한 행렬곱을 결과로 도출한다. 그러나 3차원 이상에서는 서로 다르게 동작한다. 이 두 함수의 차이가 궁금하다면 직접 검색하여 공부해보자."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a3a1d7c",
      "metadata": {
        "id": "1a3a1d7c"
      },
      "source": [
        "다음으로 einsum()함수는 행렬 연산에 관한 다양한 함수들을 다 알지 못하더라도, 이 함수 하나만을 가지고 다양한 행렬 연산을 사용자가 직접 지정해줄 수 있는 함수이다. 이 함수의 원리는 아인슈타인 표기법을 따르는데, 아인슈타인 표기법에 대해 스스로 검색하여 공부해보면 Numpy와 PyTorch에서 einsum()함수를 사용하는 예시들을 쉽게 이해할 수 있을 것이다.\n",
        "\n",
        "아래의 예시들을 직접 실행해보며 einsum()함수의 유용함을 느껴보자, einsum()함수에 대해 완벽히 이해하지 못했더라도 괜찮다. 다만 앞으로 einsum()함수의 새로운 사용 예시를 보게 되더라도 낯설고 어렵게 느끼지 말고, 익숙하게 느끼길 바란다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "beabda70",
      "metadata": {
        "id": "beabda70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c844dd63-ab92-4516-ab96-9e2a62557caa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0,  1,  2,  3,  4],\n",
              "         [ 5,  6,  7,  8,  9],\n",
              "         [10, 11, 12, 13, 14],\n",
              "         [15, 16, 17, 18, 19],\n",
              "         [20, 21, 22, 23, 24]]),\n",
              " tensor([[ 0,  1,  2],\n",
              "         [ 3,  4,  5],\n",
              "         [ 6,  7,  8],\n",
              "         [ 9, 10, 11],\n",
              "         [12, 13, 14]]),\n",
              " tensor([[  0,  -1,  -2],\n",
              "         [ -3,  -4,  -5],\n",
              "         [ -6,  -7,  -8],\n",
              "         [ -9, -10, -11],\n",
              "         [-12, -13, -14]]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "a = tc.arange(25).reshape(5,5)\n",
        "b = tc.arange(15).reshape(5,3)\n",
        "c = -tc.arange(15).reshape(5,3)\n",
        "a, b, c"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "i는 행, j는 열을 뜻함\n"
      ],
      "metadata": {
        "id": "SO5CvLLnsh_n"
      },
      "id": "SO5CvLLnsh_n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6166eb9",
      "metadata": {
        "id": "c6166eb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cc80e0d-3af9-4954-f7e9-c92ffe7a997e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(60)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# a의 대각합\n",
        "tc.einsum('ii', a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e81572d",
      "metadata": {
        "id": "7e81572d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "684133a6-b641-46b6-d545-4ccef7c9ea15"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0,  6, 12, 18, 24])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# a의 대각원소\n",
        "tc.einsum('ii->i', a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc252f98",
      "metadata": {
        "id": "bc252f98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "744ce638-21d6-4367-8310-c77519606707"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  3,  6,  9, 12],\n",
              "        [ 1,  4,  7, 10, 13],\n",
              "        [ 2,  5,  8, 11, 14]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# b의 전치행렬\n",
        "tc.einsum('ji', b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d586edc",
      "metadata": {
        "id": "6d586edc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e85a540-c205-438e-e0f9-ac8b4dc30d0d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[  0,  50, 100],\n",
              "         [165, 220, 275],\n",
              "         [360, 420, 480],\n",
              "         [585, 650, 715],\n",
              "         [840, 910, 980]]),\n",
              " tensor([[ 90, 100, 110],\n",
              "         [240, 275, 310],\n",
              "         [390, 450, 510],\n",
              "         [540, 625, 710],\n",
              "         [690, 800, 910]]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# a와 b의 행렬곱 계산 (matmul과 결과가 동일함을 확인해보기)\n",
        "tc.einsum('ij,jk->jk', a,b), tc.matmul(a,b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "976de1a0",
      "metadata": {
        "id": "976de1a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53b1f7c0-c350-4469-d2e4-bbf28dfb85e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  -5,  -50, -149, -302, -509])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# 같은 모양의 텐서 b,c의 각 행끼리의 점곱을 계산\n",
        "tc.einsum(\"ij,ij->i\",b,c)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50bdd8c5",
      "metadata": {
        "id": "50bdd8c5"
      },
      "source": [
        "#### 자동미분과 딥러닝을 위한 특수 함수"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6676ae0f",
      "metadata": {
        "id": "6676ae0f"
      },
      "source": [
        "PyTorch는 NumPy와 유사한 함수들 외에도 PyTorch만의 딥러닝을 위한 특수 함수들을 제공합니다. torch.nn 모듈에서는 딥러닝을 진행할 신경망을 구현하는 데 필요한 손실 함수(loss function), 활성 함수(activation function), 초기화 함수(initializer)의 대표적인 예시들을 제공합니다. 이러한 함수들에 대해서는 이번 실습에서는 다루지 않을 것이지만, 바로 다음 실습부터 꾸준히 여러 함수들이 등장할 예정입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1a37a44",
      "metadata": {
        "id": "e1a37a44"
      },
      "source": [
        "### Step 2 자동미분 실행하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d850545d",
      "metadata": {
        "id": "d850545d"
      },
      "source": [
        "이제 PyTorch 라이브러리의 핵심 기능인 자동미분에 대해 알아보자. PyTorch를 비롯한 대부분의 자동미분 라이브러리는 함수의 도함수(편도함수)를 직접 구하지 않는다. 그 대신 주어진 점(입력값)에서의 미분계수(편미분계수) 값을 구한다. 즉, 자동미분 라이브러리는 지정해준 점에서의 함수의 순간 기울기를 구하는 기능만을 갖고 있으며, 우리는 이를 이용하여 미분가능한 모든 함수의 모든 지점에서의 기울기를 구할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56abc047",
      "metadata": {
        "id": "56abc047"
      },
      "source": [
        "#### 텐서 객체의 '.backward()' 메서드"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e4dd1f7",
      "metadata": {
        "id": "0e4dd1f7"
      },
      "source": [
        "PyTorch에서 자동미분을 호출하기 위해 필요한 유일한 방법은 Tensor.backward()이다. 다른 텐서로부터 계산한 텐서 F에 대해 F.backward()를 호출하면, PyTorch는 F가 의존하는 모든 텐서에 대해 F의 편미분계수를 계산하도록 지시한다. 이 편미분계수들은 각각의 텐서들의 .grad 속성에 Tensor로 저장된다. 이때 몇 가지 주의사항이 있다.\n",
        "\n",
        "1. requires_grad=True:\n",
        "자동 미분을 추적하려면 텐서를 생성할 때 requires_grad=True로 설정해야 한다.\n",
        "\n",
        "2. backward() 호출:\n",
        "Tensor.backward()를 호출하면 해당 텐서로부터 계산된 모든 텐서에 대해 그래디언트(기울기)를 계산합니다. backward()는 스칼라 값에 대해서만 호출할 수 있습니다. 만약 텐서가 스칼라가 아니라면, 적절한 축소 연산을 통해 스칼라로 변환한 후 backward()를 호출해야 한다 (예: sum())."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee0edf3a",
      "metadata": {
        "id": "ee0edf3a"
      },
      "source": [
        "예를 들어 아래와 같이 x, y, z 텐서가 있고, x와 y의 함수로 정의된 f 텐서가 있는 상황에서의 편미분을 살펴보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8909fc52",
      "metadata": {
        "id": "8909fc52"
      },
      "outputs": [],
      "source": [
        "x = tc.tensor(2.0, requires_grad=True)\n",
        "y = tc.tensor(3.0, requires_grad=True)\n",
        "z = tc.tensor(4.0, requires_grad=True)\n",
        "f = x * y # tc.multiply(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9b04f19",
      "metadata": {
        "id": "d9b04f19"
      },
      "source": [
        "이 때, f.backward()를 호출하면 PyTorch가 f의 모든 편미분계수를 계산하도록 지시한다. 이는 역전파(backpropagation)라고 하는 컴퓨터가 빠르게 편미분계수를 계산할 수 있는 알고리즘을 사용하여 수행된다. 역전파 알고리즘은 딥러닝의 발전에서 빠질 수 없는 핵심적인 알고리즘이라 할 수 있는 것으로, 연쇄법칙(chain rule)에 기반한 알고리즘이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eff5c10e",
      "metadata": {
        "id": "eff5c10e"
      },
      "outputs": [],
      "source": [
        "f.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a891efdb",
      "metadata": {
        "id": "a891efdb"
      },
      "source": [
        "x와 y의 .grad() 속성을 살펴보면 $\\frac{d F}{d x}$와 $\\frac{d F}{dy}$의 값을 얻을 수 있다. .grad()는 텐서로 구해진다. z는 f가 의존하는 변수 텐서가 아니므로 .grad() 속성에 값이 없다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "692b2f01",
      "metadata": {
        "id": "692b2f01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc152414-0b84-41d2-aa97-9e925e137fde"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "x.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "208b6de2",
      "metadata": {
        "id": "208b6de2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1091309c-5fbb-4b15-b3ac-219e1d622ac2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "y.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d5d2ed2",
      "metadata": {
        "id": "7d5d2ed2"
      },
      "outputs": [],
      "source": [
        "z.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab7cd692",
      "metadata": {
        "id": "ab7cd692"
      },
      "source": [
        "이번에는 x, y, 그리고 x와 y로부터 구해지는 f까지 세 텐서에 의존하는 텐서 F의 모든 편미분계수를 계산해보자. 즉, F(f(x, y), x, y)인 경우를 살펴볼 것이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cebffb7",
      "metadata": {
        "id": "2cebffb7"
      },
      "outputs": [],
      "source": [
        "x = tc.tensor(2.0, requires_grad=True)\n",
        "y = tc.tensor(3.0, requires_grad=True)\n",
        "f = x * y\n",
        "f.retain_grad()\n",
        "F = f + x - 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a90c30f",
      "metadata": {
        "id": "1a90c30f"
      },
      "outputs": [],
      "source": [
        "F.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cb35f93",
      "metadata": {
        "id": "5cb35f93"
      },
      "source": [
        "f의 .grad() 속성을 살펴보면 $\\frac{\\partial F}{\\partial f}$의 값을 얻을 수 있다.\n",
        "y의 .grad() 속성을 살펴보면 $\\frac{\\partial F}{\\partial y} = \\frac{\\partial F}{\\partial f}\\frac{\\partial f}{\\partial y}$의 값을 얻을 수 있다.\n",
        "\n",
        "마지막으로 x의 경우, t = x에 대해 F = f + t - 2로 쓸 수 있다. 이렇게 생각하고 x의 .grad() 속성을 살펴보면 $\\frac{\\partial F}{\\partial x} = \\frac{\\partial F}{\\partial f}\\frac{\\partial f}{\\partial x} + \\frac{\\partial F}{\\partial t}\\frac{\\partial t}{\\partial x}$의 값을 얻을 수 있다.\n",
        "\n",
        "주의사항으로 PyTorch에서 특정 텐서의 그래디언트를 계산하기 위해서는 그 텐서에 대해 직접적으로 requires_grad=True를 설정하고, 필요하다면 중간 텐서에 대해서도 retain_grad() 메소드를 호출해야 한다. retain_grad()는 중간 텐서의 그래디언트를 저장하도록 한다. f.retain_grad() 코드가 없다면 어떻게 실행되는지 확인해보는 것도 좋을 것이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17a4384e",
      "metadata": {
        "id": "17a4384e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87776ec6-975c-42f4-d07b-8181337a1a55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "f.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3da1420",
      "metadata": {
        "id": "c3da1420",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd7609b5-b68c-4205-ac92-92f442f38519"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "y.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0f394a3",
      "metadata": {
        "id": "f0f394a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "752ff581-0a74-4567-8834-e6ded441bd4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06825fb4",
      "metadata": {
        "id": "06825fb4"
      },
      "source": [
        "f와 F가 의존하는 모든 변수들이 PyTorch의 텐서로 저장되어 있었고, f와 F를 이루는 모든 수학적 연산이 PyTorch에서 제공하는 함수였기 때문에 PyTorch를 통해 F의 모든 편미분계수를 구할 수 있었다. 이렇게 구한 편미분계수들로부터 함수의 그래디언트를 이용하는 경사하강법을 쉽게 수행할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05aac9d3",
      "metadata": {
        "id": "05aac9d3"
      },
      "source": [
        "# 문제: 텐서 객체의 backward() 메서드 사용\n",
        "\n",
        "여러가지 수식으로 정의된 x에 대한 함수 F에 대해, x=2.5에서 $\\frac{d F}{d x}\\big|_{x=2.5}$를 구해보자."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1번 문제"
      ],
      "metadata": {
        "id": "MAGBsn7xGd1k"
      },
      "id": "MAGBsn7xGd1k"
    },
    {
      "cell_type": "markdown",
      "id": "f35f6a9d",
      "metadata": {
        "id": "f35f6a9d"
      },
      "source": [
        "1. $F(x)=x^2$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ad9f204",
      "metadata": {
        "id": "1ad9f204",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0291d914-1f5a-4c1f-dee4-8f266797e2b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5.)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# 여기에 코드 작성\n",
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "F = x**2\n",
        "F.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1번 문제 정답"
      ],
      "metadata": {
        "id": "xfCuA6MxGEHh"
      },
      "id": "xfCuA6MxGEHh"
    },
    {
      "cell_type": "code",
      "source": [
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "F = x**2\n",
        "F.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "id": "hA-iU8diGMxo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f599b4e-a3a6-43e0-a089-de03c83599f8"
      },
      "id": "hA-iU8diGMxo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5.)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1번 문제 출력 결과 : tensor(5.)"
      ],
      "metadata": {
        "id": "YIOuj1FMGPMw"
      },
      "id": "YIOuj1FMGPMw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2번 문제"
      ],
      "metadata": {
        "id": "ekFW_3OnGSdU"
      },
      "id": "ekFW_3OnGSdU"
    },
    {
      "cell_type": "markdown",
      "id": "7a5cd97f",
      "metadata": {
        "id": "7a5cd97f"
      },
      "source": [
        "2. $F(x)=\\cos{\\sqrt{x}}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f62fd0dd",
      "metadata": {
        "id": "f62fd0dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc6fa892-442e-48de-c6a4-6938669cbc0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.3162)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# 여기에 코드 작성\n",
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "F = tc.cos(tc.sqrt(x))\n",
        "F.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2번 문제 정답"
      ],
      "metadata": {
        "id": "G1rUUHZFGi-3"
      },
      "id": "G1rUUHZFGi-3"
    },
    {
      "cell_type": "code",
      "source": [
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "F = tc.cos(tc.sqrt(x))\n",
        "F.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "id": "4V1iRDD3GijE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df50fb06-f761-4953-ae3b-79b306b496aa"
      },
      "id": "4V1iRDD3GijE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.3162)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2번 문제 출력 결과 : tensor(-0.3162)"
      ],
      "metadata": {
        "id": "dIrwUZzyGibE"
      },
      "id": "dIrwUZzyGibE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3번 문제"
      ],
      "metadata": {
        "id": "aBe8aYzXGr3G"
      },
      "id": "aBe8aYzXGr3G"
    },
    {
      "cell_type": "markdown",
      "id": "f994e9f9",
      "metadata": {
        "id": "f994e9f9"
      },
      "source": [
        "3. $F(x)=2+3x-5x^2$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9aba45f7",
      "metadata": {
        "id": "9aba45f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e593a186-5341-4d7c-89d0-32092651189d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-22.)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# 여기에 코드 작성\n",
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "F = 2 + 3*x - 5*x**2\n",
        "F.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3번 문제 정답"
      ],
      "metadata": {
        "id": "b-l8ieGVGv3M"
      },
      "id": "b-l8ieGVGv3M"
    },
    {
      "cell_type": "code",
      "source": [
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "F = 2+3*x-5*x**2\n",
        "F.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "id": "mEgwk9LhGuT6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eefb504-8c1b-4ce2-91b5-67597ac98eec"
      },
      "id": "mEgwk9LhGuT6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-22.)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3번 문제 출력 결과 : tensor(-22.)"
      ],
      "metadata": {
        "id": "gOabd2fPGul7"
      },
      "id": "gOabd2fPGul7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4번 문제"
      ],
      "metadata": {
        "id": "0oTiFRY5G2tE"
      },
      "id": "0oTiFRY5G2tE"
    },
    {
      "cell_type": "markdown",
      "id": "aa6ca763",
      "metadata": {
        "id": "aa6ca763"
      },
      "source": [
        "4. $F(x)=e^{lnx}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d028375e",
      "metadata": {
        "id": "d028375e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dae228b-e7aa-4c60-8314-9785da4485ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "# 여기에 코드 작성\n",
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "F = tc.exp(tc.log(x))\n",
        "F.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4번 문제 정답"
      ],
      "metadata": {
        "id": "rbGPZ_ydG53A"
      },
      "id": "rbGPZ_ydG53A"
    },
    {
      "cell_type": "code",
      "source": [
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "F = tc.exp(tc.log(x))\n",
        "F.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "id": "dLQKI_84G5Sa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "705d7a8b-1766-43a5-a3ad-f693bedab067"
      },
      "id": "dLQKI_84G5Sa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4번 문제 출력 결과 : tensor(1.)"
      ],
      "metadata": {
        "id": "G49bEx7jG5e4"
      },
      "id": "G49bEx7jG5e4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5번 문제"
      ],
      "metadata": {
        "id": "9UFMZxcHHEX5"
      },
      "id": "9UFMZxcHHEX5"
    },
    {
      "cell_type": "markdown",
      "id": "979502fa",
      "metadata": {
        "id": "979502fa"
      },
      "source": [
        "5. $F(x)=(2xf(x))^2-f(x), f(x)=x^2$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e333cb51",
      "metadata": {
        "id": "e333cb51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db024d6c-7d89-4d71-f580-20b9e6bb1b46"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2338.7500)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "# 여기에 코드 작성\n",
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "F = ((2*x)*x**2)**2 - x**2\n",
        "F.backward()\n",
        "x.grad\n",
        "\n",
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "f = x**2\n",
        "F = (2*x*f)**2 - f\n",
        "F.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5번 문제 정답"
      ],
      "metadata": {
        "id": "U0_bPo_AHGKV"
      },
      "id": "U0_bPo_AHGKV"
    },
    {
      "cell_type": "code",
      "source": [
        "x = tc.tensor(2.5, requires_grad=True)\n",
        "f = x**2\n",
        "F = (2*x*f)**2-f\n",
        "F.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "id": "PmQlhnDvHGbA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f393b4e4-9ed0-4e93-ba34-49c9eb5564d0"
      },
      "id": "PmQlhnDvHGbA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2338.7500)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5번 문제 출력 결과 : tensor(2338.7500)"
      ],
      "metadata": {
        "id": "mfseKPKcHGwV"
      },
      "id": "mfseKPKcHGwV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# -"
      ],
      "metadata": {
        "id": "1wT96P_lHMrw"
      },
      "id": "1wT96P_lHMrw"
    },
    {
      "cell_type": "markdown",
      "id": "72ea07a0",
      "metadata": {
        "id": "72ea07a0"
      },
      "source": [
        "#### .grad 속성의 초기화"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e8e4d75",
      "metadata": {
        "id": "0e8e4d75"
      },
      "source": [
        "경사하강법을 수행할 때, 텐서와 관련된 편미분계수를 반복적으로 구해야 한다. 따라서, 경사하강을 반복할 때마다 사이사이에 편미분계수를 폐기해야 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fce6da3",
      "metadata": {
        "id": "6fce6da3"
      },
      "source": [
        "backward()연산을 진행한 함수가 의존하는 텐서들 중 하나의 .grad 속성을 초기화하는 방법은 다음과 같이 두가지가 있다. 아래와 같은 상황을 생각해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45b77985",
      "metadata": {
        "id": "45b77985",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c949bea-c5a2-43ff-c8f1-f864d5084408"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "x = tc.tensor(2.0, requires_grad=True)\n",
        "f = x**2\n",
        "f.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b0e92ca",
      "metadata": {
        "id": "9b0e92ca"
      },
      "source": [
        "그래디언트를 초기화하지 않으면, 추가 연산 후 backward()를 호출해도 이전 값에 누적되지 않고 덮어쓴다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7a13d5b",
      "metadata": {
        "id": "c7a13d5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bf77ffc-2f71-4baa-f4cd-689af6e37616"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(8.)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "g = x**2\n",
        "g.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6477d424",
      "metadata": {
        "id": "6477d424"
      },
      "source": [
        "Tensor.grad를 호출하여 해당 텐서의 .grad 속성을 직접적으로 None으로 재설정할 수도 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71cbc888",
      "metadata": {
        "id": "71cbc888"
      },
      "outputs": [],
      "source": [
        "x.grad = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d3fb5eb",
      "metadata": {
        "id": "0d3fb5eb"
      },
      "outputs": [],
      "source": [
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6de8423c",
      "metadata": {
        "id": "6de8423c"
      },
      "source": [
        "#### PyTorch와 Numpy의 관계"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4133bbb6",
      "metadata": {
        "id": "4133bbb6"
      },
      "source": [
        "우리는 앞의 내용에서 PyTorch에서 NumPy의 다양한 수학함수들을 동일하게 정의해두었다는 것을 충분히 확인했다.\n",
        "\n",
        "PyTorch의 텐서 객체는 NumPy 배열과 비교했을 때 별로 새롭지 않다. 텐서 객체는 Numpy 배열에 대한 정보를 기본으로 가지고 있으며, 단지 배열이 관련된 수학적 연산들을 추적하는 추가 역할을 할 뿐이다. 수학적 연산에 대한 추적은 자동미분을 위해 추가된 역할이라고 볼 수 있다.\n",
        "\n",
        "이러한 관계성에 의해 우리는 텐서를 한꺼풀 벗겨내어 NumPy 배열을 얻을 수 있다. 다음의 텐서 x에 대해 NumPy 배열로 만드는 세 가지 방법을 확인해보자."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7I3HEHz_gIFV",
      "metadata": {
        "id": "7I3HEHz_gIFV"
      },
      "source": [
        "먼저, 기본 텐서의 경우 numpy()를 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55472dc7",
      "metadata": {
        "id": "55472dc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2d45d64-0665-4890-e9db-1fb88e02435c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "x = tc.tensor([0.0,1.0,2.0,3.0])\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ef96a8b",
      "metadata": {
        "id": "1ef96a8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50256938-d68d-4cf5-8b0c-a520ff265d2e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 2., 3.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "x.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e22945e",
      "metadata": {
        "id": "9e22945e"
      },
      "source": [
        "두번째로, grad 정보가 포함된 경우 detach().numpy()를 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac022abd",
      "metadata": {
        "id": "ac022abd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "598e05d5-5a8b-492a-b3b2-befd3d02595f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "# requires_grad=True가 있으면 detach()\n",
        "x = tc.tensor([0.0,1.0,2.0,3.0], requires_grad=True)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38a70485",
      "metadata": {
        "id": "38a70485",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfb5f770-d7c2-4411-a34b-99fd2028b53e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 2., 3.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "x.detach().numpy() # numpy는 grad의 값이 없으므로 detach()를 같이 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CqdEZEnAg9p9",
      "metadata": {
        "id": "CqdEZEnAg9p9"
      },
      "source": [
        "세번째로, gpu에 선언된 텐서의 경우 cpu().numpy()를 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uwST0Z-7g596",
      "metadata": {
        "id": "uwST0Z-7g596",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e810331-66a6-4fc8-d398-a54f856b3bbc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3.], device='cuda:0', grad_fn=<ToCopyBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "x = tc.tensor([0.0,1.0,2.0,3.0], requires_grad=True).cuda()\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2wax3zVOhMkf",
      "metadata": {
        "id": "2wax3zVOhMkf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70c26dbd-d9ee-4879-a3b7-337ed511d432"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 2., 3.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "x.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61fa582a",
      "metadata": {
        "id": "61fa582a"
      },
      "source": [
        "#### 편미분계수 계산 시 상수 텐서와 변수 텐서"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "364ca3a4",
      "metadata": {
        "id": "364ca3a4"
      },
      "source": [
        "앞서 살펴본 머신러닝 모델에 대해 경사하강법을 진행하는 경우를 생각해보자.\n",
        "\n",
        "머신러닝 모델을 다음과 같이 정의할 때\n",
        "\\begin{equation}\n",
        "\\mathscr{L}\\big(w_1, ..., w_M ; (x_n, y_n)_{n=0}^{N-1}\\big)\n",
        "\\end{equation}\n",
        "\n",
        "경사하강법을 수행하기 위해 우리는 $\\frac{d\\mathscr{L}}{dw_i}$를 각각의 $w_i$에 대해 계산해야 한다. 그러나, $\\frac{d\\mathscr{L}}{dx_i}$는 필요하지 않다. 특히, 입력 데이터셋이 크고 복잡해질수록, 필요없는 수많은 편미분계수를 일일이 계산하는 것은 쓸데없이 많은 비용이 드는 일이다.\n",
        "\n",
        "위에서 배운대로라면, PyTorch 텐서의 .backward() 메서드는 $\\mathscr{L}$를 이루는 모든 변수 텐서들에 대해 편미분계수를 계산한다. 따라서, 우리는 편미분계수 계산이 필요없는 데이터들을 변수 텐서가 아니라 상수 텐서로 표현함으로써 자동으로 .backward() 계산에서 배제되도록 할 것이다. 상수 텐서로 취급할 수 있는 방법을 알아보자."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "667de722",
      "metadata": {
        "id": "667de722"
      },
      "source": [
        "PyTorch의 텐서 객체를 생성할 때 requires_grad=False를 사용하여 상수 텐서를 생성할 수 있다. requires_grad=False로 설정된 텐서는 그래디언트 계산에 포함되지 않는다. 기본값이 requires_grad=False이므로, 특별히 지정하지 않아도 된다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28053219",
      "metadata": {
        "id": "28053219"
      },
      "outputs": [],
      "source": [
        "x = tc.tensor(1.)\n",
        "y = tc.tensor(2., requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29c2bac7",
      "metadata": {
        "id": "29c2bac7"
      },
      "outputs": [],
      "source": [
        "F = x * y\n",
        "print(F)\n",
        "F.backward()\n",
        "print(F)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ba47cc3",
      "metadata": {
        "id": "0ba47cc3"
      },
      "outputs": [],
      "source": [
        "F.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fb9cb00",
      "metadata": {
        "id": "6fb9cb00"
      },
      "outputs": [],
      "source": [
        "x.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9355969c",
      "metadata": {
        "id": "9355969c"
      },
      "outputs": [],
      "source": [
        "y.grad is None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47018679",
      "metadata": {
        "id": "47018679"
      },
      "source": [
        "추가적으로, 상수 텐서만으로 정의된 텐서의 경우에는 어떤 연산을 적용하더라도 상수 텐서가 생성된다. 따라서, 이렇게 얻은 상수 텐서에 대해서는 .backward() 메서드는 에러를 발생시킨다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9be9f9c8",
      "metadata": {
        "id": "9be9f9c8"
      },
      "outputs": [],
      "source": [
        "x = tc.tensor(1.)\n",
        "y = tc.tensor(2.)\n",
        "F = x + y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae6005a5",
      "metadata": {
        "id": "ae6005a5"
      },
      "outputs": [],
      "source": [
        "F.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2b85dc5",
      "metadata": {
        "id": "d2b85dc5"
      },
      "outputs": [],
      "source": [
        "F.grad is None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b10bbdab",
      "metadata": {
        "id": "b10bbdab"
      },
      "source": [
        "### Step 3. 다차원 텐서의 자동미분 실행하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5989cb5b",
      "metadata": {
        "id": "5989cb5b"
      },
      "source": [
        "#### 다차원 텐서에 대해 정의된 함수에서의 자동미분"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95ac6652",
      "metadata": {
        "id": "95ac6652"
      },
      "source": [
        "지금까지는 하나의 스칼라 변수로 이루어진 0차원 텐서에 대해 정의된, 간단한 함수에 대해서만 자동미분을 실행해보았다. 그런데 텐서 객체는 다차원의 배열을 나타낼 수 있다. 따라서 다차원 텐서에 대해 정의된 함수에서 자동미분이 실행되는 방법을 알면 계산을 편리하게 할 수 있다.\n",
        "\n",
        "다차원 텐서와 관련된 .grad 속성을 어떻게 해석해야 할까? 한마디로 표현하면, 텐서의 각 원소를 스칼라 값 변수로 해석하면 된다. 즉, 다차원 텐서를 스칼라 변수들의 집합으로 보면 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88c0e308",
      "metadata": {
        "id": "88c0e308"
      },
      "source": [
        "이렇게만 말해서는 이해가 잘 가지 않을 것이다. 다음과 같은 계산을 통해 자세히 알아보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c211a0be",
      "metadata": {
        "id": "c211a0be"
      },
      "outputs": [],
      "source": [
        "tensor = tc.tensor([2.0, 4.0, 8.0], requires_grad=True)\n",
        "arr = tc.tensor([-1.0, 2.0, 0], requires_grad=True)\n",
        "F = (arr * tensor ** 2).sum()\n",
        "F.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9a0d070",
      "metadata": {
        "id": "b9a0d070"
      },
      "source": [
        "위의 코드에서 정의된 함수 F를 풀어서 쓰면 $F = -1\\:(x_0)^2 + 2\\:(x_1)^2 + 0\\:(x_2)^2$이다. 그리고 다차원 텐서의 각 원소를 스칼라 값 변수로 해석한다는 것은, $\\mathrm{tensor} = [x_0, x_1, x_2]$로 보겠다는 뜻이다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afbb87af",
      "metadata": {
        "id": "afbb87af"
      },
      "source": [
        "이때, tensor.grad에는 어떤 값이 저장되어야 타당할까? tensor의 각 스칼라 변수들로 편미분한 값들을 tensor와 같은 shape의 배열로 저장하면 좋을 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fc1254d",
      "metadata": {
        "id": "1fc1254d"
      },
      "source": [
        "\\begin{align}\n",
        "{\\nabla}F &= \\big[\\frac{\\partial F}{\\partial x_0},\\frac{\\partial F}{\\partial x_1},\\frac{\\partial F}{\\partial x_2}\\big]\\\\\n",
        "&= \\big[-2x_0,\\:4x_1,\\:0x_2\\big]\\\\\n",
        "{\\nabla}F\\big|_{x_0=2, x_1=4, x_2=8} &= \\big[-4,\\:16,\\:0\\big]\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd9e4e53",
      "metadata": {
        "id": "cd9e4e53"
      },
      "source": [
        "실제로 tensor.grad 는 tensor에 저장된 특정 값에서의 ${\\nabla}F$ 를 저장한다. 다음 코드를 실행하여 확인해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff494ccb",
      "metadata": {
        "id": "ff494ccb"
      },
      "outputs": [],
      "source": [
        "tensor.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6637697f",
      "metadata": {
        "id": "6637697f"
      },
      "source": [
        "일반화하여 표현하면 다음과 같다. tensor의 각 원소는 스칼라 값 변수로 해석할 수 있고, tensor.grad에서 대응되는 위치의 요소는 해당 변수에 대한 미분계수이다.\n",
        "\n",
        "$\\text{tensor}[x_0, \\dots, x_{(N-1)}] \\rightarrow \\text{tensor.grad}[x_0, \\dots, x_{(N-1)}] = {\\nabla}F = \\big[\\frac{\\partial F}{\\partial x_0},\\dots,\\frac{\\partial F}{\\partial x_{(N-1)}}\\big]$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b333799",
      "metadata": {
        "id": "9b333799"
      },
      "source": [
        "#### 벡터화된 자동미분"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4eca391",
      "metadata": {
        "id": "c4eca391"
      },
      "source": [
        "방금 다차원 텐서에 의해 정의된 스칼라 함수에 대한 자동미분에 대해 배웠다. 이번에는 스칼라 함수가 아닌, 벡터 함수에 대해 자동미분을 실행할 때는 어떻게 실행되는지 알아보자.\n",
        "\n",
        ".backward() 메서드를 호출한 최종 함수가 스칼라가 아니라 벡터 함수라면, PyTorch는 최종 함수를 스칼라로 다 합친 후에 역전파를 진행해야한다.\n",
        "\n",
        "이렇게 합친 $\\sum F$는 스칼라이기 때문에 $\\frac{\\partial (\\sum F)}{\\partial x_{i}}$ 또한 스칼라이다. 따라서 위에서 살펴본 바와 같이 tensor와 tensor.grad는 항상 같은 shape을 갖는다.\n",
        "\n",
        "이렇게만 말해서는 이해가 가지 않으니, 다음과 같은 계산을 통해 알아보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43a7cb94",
      "metadata": {
        "id": "43a7cb94"
      },
      "outputs": [],
      "source": [
        "tensor = tc.linspace(-5, 5, 20, requires_grad=True)\n",
        "F = tensor ** 2  # shape-(20)인 텐서\n",
        "F_sum = F.sum()\n",
        "F_sum.backward()\n",
        "#F.backward()\n",
        "tensor.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d4fce29",
      "metadata": {
        "id": "6d4fce29"
      },
      "source": [
        "위의 코드에서 정의된 함수 F는 $F= \\big[x_0 ^2,\\ \\dots, \\; x^2_{99} \\big]$이다. 그리고 PyTorch에서 F_sum.backward()를 실행할 때 이를 스칼라로 다 합친다는 것은, $\\sum {F} = x_0 ^2 + \\dots + x^2_{99}$로 합친 후 이에 대해 .backward()를 실행하겠다는 뜻이다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f3bc6ee",
      "metadata": {
        "id": "2f3bc6ee"
      },
      "source": [
        "그런데 여기서 의문이 생긴다. 다변수 벡터함수 $F$의 편미분 계수들을 구하기 위해서는 야코비 행렬을 구하는 게 합당해 보인다. 그런데 $\\sum F$에 대해 .backward()를 실행시키는 것은 매우 다른 결과를 불러온다.\n",
        "\n",
        "각 성분함수에 대한 편미분 계수들을 일일이 구하지 못하고, 대신 성분함수들의 합에 대한 편미분 계수 $\\frac{\\partial (F_0+F_1+ \\cdots + F_{N-1})}{\\partial x_i}$ 만을 구하게 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85f872b3",
      "metadata": {
        "id": "85f872b3"
      },
      "source": [
        "왜 PyTorch에서는 자동미분 기능을 이렇게 구현한 것일까? 만약 다변수 벡터함수 의 각 성분함수들이 각각 독립인 입력 변수에 대해 정의되었다면, 즉 독립인 $x_0, x_1,\\cdots, x_{(N-1)}$ 에 대해 $F=[F_0(x_0), F_1(x_1), \\cdots, F_{N-1}(x_{(N-1)})]$ 로 정의되었다면 $\\sum F$에 대해 .backward()를 실행시키는 것은 의미있는 행위가 된다. 유효한 모든 편미분 계수를 $\\big[\\frac{\\partial F_{0}}{\\partial x_0},\\dots,\\frac{\\partial F_{N-1}}{\\partial x_{(N-1)}}\\big]$ 와 같이 구할 수 있게 되기 때문이다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67aadde5",
      "metadata": {
        "id": "67aadde5"
      },
      "source": [
        "다시 위의 예시로 돌아가보자.  $F= \\big[x_0 ^2,\\ \\dots, \\; x^2_{99} \\big]$에 대해 .backward()를 실행시킨 것은  $\\sum{F} = x_0 ^2 + \\dots + x^2_{99}$에 대해 .backward()를 실행시킨 것과 같다. 그리고 이후에 입력 tensor $\\rm\\textbf{x} = \\big[ x_0, x_1,\\cdots, x_{(N-1)}\\big]$ 에 대한 tensor.grad를 구하면 입력 tensor $\\rm\\textbf{x}$와 shape이 동일한 ${\\nabla}(\\Sigma{{F}}) = \\big[2x_0,\\ \\dots, \\; 2x_{99} \\big]$ 가 구해진다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94d7fc45",
      "metadata": {
        "id": "94d7fc45"
      },
      "source": [
        "이 계산은 결국, 100개의 독립적인 값들에 대해 함수 $f(x) = x ^ 2$ 의 편미분계수 값 ($\\frac{\\mathrm{d}f}{\\mathrm{d}x} = 2x$)을 한번에 계산한 것과 같았다. 따라서, PyTorch를 이용하여 독립적인 값들에 대한 성분함수로 이루어진 다변수 벡터 함수의 미분을 구하는 기능은, 여러 개의 독립적인 데이터를 하나의 텐서로 묶어서 동일한 계산을 한 번에 수행할 때 큰 이점이 있다. 신경망에 대해 배우고 본격적인 딥러닝에 대해 실습할 때 도움이 될 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b44d37d0",
      "metadata": {
        "id": "b44d37d0"
      },
      "source": [
        "### 문제: 도함수의 그래프 그리기\n",
        "\n",
        ".backward() 메서드를 이용하면 특정 점에서의 그래디언트만 구할 수 있고, 도함수의 식과 그래프는 알 수 없다. 그런데, 벡터화된 자동미분을 이용하면 여러 점에서의 편미분계수 값을 한번에 구할 수 있으므로, matplotlib을 통해 그래프를 찍을 수 있게 된다.\n",
        "\n",
        "1. 벡터화된 자동미분을 수행하는 다음의 함수를 완성해보자. matplotlib에 관한 실습1의 내용을 잘 떠올리면서 작성해보자. (주의: matplotlib에 데이터를 전달할 때는 torch의 텐서가 아닌, 널리 알려진 라이브러리인 NumPy의 배열을 사용하는 것이 좋습니다.)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " $f(x) = \\sin{(2x)}\\; \\cos{(x)}\\; e^{-x/3}$의 그래프와 그 도함수를 torch를 이용해서 그려보자."
      ],
      "metadata": {
        "id": "n-UzYgKBZkV9"
      },
      "id": "n-UzYgKBZkV9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63b190cf",
      "metadata": {
        "id": "63b190cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2e2852f-ad51-4b07-fa20-e973de9cc74b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0.0000,  0.0020,  0.0040,  ..., -0.0273, -0.0273, -0.0273],\n",
              "        grad_fn=<MulBackward0>),\n",
              " tensor([2.0000, 1.9987, 1.9973,  ..., 0.0021, 0.0022, 0.0024]))"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "x = tc.linspace(0, 10, 10000, requires_grad=True)\n",
        "y = tc.sin(2*x)*tc.cos(x)*tc.exp(-x/3)\n",
        "y_sum = y.sum()\n",
        "y_sum.backward()\n",
        "y, x.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a956957d",
      "metadata": {
        "id": "a956957d"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def plot_func_and_deriv(x, func):\n",
        "    \"\"\"\n",
        "    함수 func(x)와 도함수 dfunc/dx를 같은 축(axis) 상에 그리는 함수\n",
        "\n",
        "    매개변수 (Parameters)\n",
        "    ----------\n",
        "    x : PyTorch.Tensor, shape-(N,)\n",
        "        함수 func(x)와 도함수 dfunc/dx를 그리는 x의 정의역\n",
        "\n",
        "    func: Callable[[Tensor], Tensor]\n",
        "        x에 대한 일변수 함수\n",
        "\n",
        "    반환 값 (Returns)\n",
        "    -------\n",
        "    Tuple[Figure, Axis]\n",
        "        matplotlib로 그래프를 그리기 위한 fig와 ax\n",
        "    \"\"\"\n",
        "    x = tc.tensor(x, requires_grad=True)\n",
        "    y = func(x)\n",
        "    y.sum().backward()\n",
        "\n",
        "    # 여기에 코드 작성\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.plot(x.detach().numpy(), y.detach().numpy(), c=\"red\")\n",
        "    ax.plot(x.detach().numpy(), x.grad.detach().numpy(), c=\"blue\")\n",
        "    ax.grid(True)\n",
        "\n",
        "    return fig, ax"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6565d15f",
      "metadata": {
        "id": "6565d15f"
      },
      "source": [
        "2. 이제 위에서 작성한 함수를 이용하여 구간 $[0, 10]$를 균등하게 10,000개로 나눈 정의역에 대해 함수 $f(x) = \\sin{(2x)}\\; \\cos{(x)}\\; e^{-x/3}$와 그 도함수의 그래프를 그려보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72733202",
      "metadata": {
        "id": "72733202"
      },
      "outputs": [],
      "source": [
        "def f(x):\n",
        "    # 여기에 코드 작성\n",
        "    return tc.sin(2*x)*tc.cos(x)*tc.exp(-x/3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c5f677e",
      "metadata": {
        "id": "7c5f677e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "outputId": "29724a13-a3d1-4161-837c-50ebd2a79406"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-66-2325083283.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = tc.tensor(x, requires_grad=True)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "x = tc.linspace(0, 10, 10000)\n",
        "fig, ax = plot_func_and_deriv(x, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0a1f72a",
      "metadata": {
        "id": "c0a1f72a"
      },
      "source": [
        "### Step 4. Torch의 자동미분을 이용한 경사하강법"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72b0de77",
      "metadata": {
        "id": "72b0de77"
      },
      "source": [
        "#### 경사하강법 코드 수정하기 (1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a2062d0",
      "metadata": {
        "id": "6a2062d0"
      },
      "source": [
        "자동미분을 이용하면 경사하강법을 쉽게 구현할 수 있다. 연습을 위해 간단한 일변수 함수에 대해 경사하강법을 수행해볼 것이다. 앞선 예제에서도 다룬적 있는 함수 $\\mathscr{L}(w) = w^2$에 대한 경사하강법을 수행하며 자동미분을 잘 활용해보자.\n",
        "\n",
        "앞선 예제에서는 $\\mathscr{L}(w) = w^2$의 도함수가 $\\frac{d \\mathscr{L}}{d w} = 2w$임을 알고 있는 상태에서 경사하강법 함수 descent_down_parabola()를 작성해보았다.\n",
        "\n",
        "```python\n",
        "def descent_down_parabola(w_start, learning_rate, num_steps):\n",
        "    w_values = [w_start]\n",
        "    for _ in range(num_steps):\n",
        "        w_old = w_values[-1]\n",
        "        w_new = w_old - learning_rate * (2 * w_old)\n",
        "        w_values.append(w_new)\n",
        "    return np.array(w_values)\n",
        "```\n",
        "\n",
        "이번에는 도함수를 모르는 $\\mathscr{L}(w)$에 대해서도 적용할 수 있는, 자동미분을 이용한 경사하강법 함수를 작성해보자. $w$의 값을 PyTorch 텐서로 저장한 후, $\\mathscr{L}(w)$를 $w$의 식으로 정의해주어, .backward() 메서드를 사용하여 편미분계수를 구할 수 있다.\n",
        "\n",
        "아래의 경사하강법 공식에 따라 자동미분을 이용한 경사하강법을 프로그래밍으로 구현해보자.\n",
        "\n",
        "\\begin{equation}\n",
        "w_{\\mathrm{new}} = w_{\\mathrm{old}} - \\delta \\frac{\\mathrm{d}\\mathscr{L}}{\\mathrm{d}w}\\big|_{w_{\\mathrm{old}}}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2da681a1",
      "metadata": {
        "id": "2da681a1"
      },
      "source": [
        "다음과 같이 $w$의 시작점과 학습률 $\\delta$, 몇 단계 반복할 것인지가 주어졌다고 하자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "941881f8",
      "metadata": {
        "id": "941881f8"
      },
      "outputs": [],
      "source": [
        "w = tc.tensor([10.0], requires_grad=True)\n",
        "learning_rate = 0.3\n",
        "num_steps = 20"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64bfcec4",
      "metadata": {
        "id": "64bfcec4"
      },
      "source": [
        "이러한 상황에 대해 아래의 코드를 채워 경사하강법을 수행하는 코드를 작성해보자. 제대로 코드를 작성한다면, 다음과 같이 $w=0$으로 서서히 가까워지는 결과가 출력될 것이다.\n",
        "```\n",
        "Tensor(4.)\n",
        "Tensor(1.6)\n",
        "Tensor(0.64)\n",
        "Tensor(0.256)\n",
        "Tensor(0.1024)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "7fda26a0",
      "metadata": {
        "id": "7fda26a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bca3a45-478e-4c3d-e1cb-821f97a3218b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4.], requires_grad=True)\n",
            "tensor([1.6000], requires_grad=True)\n",
            "tensor([0.6400], requires_grad=True)\n",
            "tensor([0.2560], requires_grad=True)\n",
            "tensor([0.1024], requires_grad=True)\n",
            "tensor([0.0410], requires_grad=True)\n",
            "tensor([0.0164], requires_grad=True)\n",
            "tensor([0.0066], requires_grad=True)\n",
            "tensor([0.0026], requires_grad=True)\n",
            "tensor([0.0010], requires_grad=True)\n",
            "tensor([0.0004], requires_grad=True)\n",
            "tensor([0.0002], requires_grad=True)\n",
            "tensor([6.7109e-05], requires_grad=True)\n",
            "tensor([2.6844e-05], requires_grad=True)\n",
            "tensor([1.0737e-05], requires_grad=True)\n",
            "tensor([4.2950e-06], requires_grad=True)\n",
            "tensor([1.7180e-06], requires_grad=True)\n",
            "tensor([6.8719e-07], requires_grad=True)\n",
            "tensor([2.7488e-07], requires_grad=True)\n",
            "tensor([1.0995e-07], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "for _ in range(num_steps):\n",
        "    ℒ = w ** 2\n",
        "    ℒ.backward()\n",
        "    # 여기에 코드 작성\n",
        "\n",
        "    #  블록 안에서 w를 업데이트. 이는 PyTorch가 이 블록 내의 연산을 추적하지 않도록 한다.\n",
        "    with tc.no_grad():\n",
        "        w -= learning_rate * w.grad\n",
        "    #w의 그래디언트를 초기화. 이를 통해 다음 단계에서 그래디언트가 누적되지 않도록 한다.\n",
        "    w.grad = None\n",
        "\n",
        "    print(w)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "604b8e15",
      "metadata": {
        "id": "604b8e15"
      },
      "source": [
        "그런데 코드를 작성할 때, 한가지 생각해볼만한 부분이 있다. 위의 코드를 완성하여 원하는 출력값도 제대로 얻었다면, 아래의 두 코드와 자신의 답변을 비교해보자. 꼭 먼저 코드를 직접 작성해본 후에 답변을 확인하길 바란다.\n",
        "\n",
        "다음의 두 코드는 모두 원하는 출력값을 얻게 해주는 코드이다.\n",
        "첫번째 코드는 다음과 같다.\n",
        "```python\n",
        "w = w - learning_rate * w.grad\n",
        "```\n",
        "두번째 코드는 다음과 같다.\n",
        "```python\n",
        "w.data -= learning_rate * w.grad\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "205b2767",
      "metadata": {
        "id": "205b2767"
      },
      "source": [
        "두 코드는 동일한 출력값을 얻게 해줄 뿐 아니라, 사실상 같은 의미라고 느껴진다. 그리고 첫번째 코드가 우리가 알고 있는 공식에 더 가까원 형태이기 때문에 좀 더 직관적이다. 그러나, 두번째 코드는 두가지 이점이 있다.\n",
        "\n",
        "첫째로 컴퓨터 계산 속도를 최적화할 수 있다. 앞서 PyTorch의 텐서는 NumPy 배열의 수학적 연산들을 추적하는 추가 기능을 갖고 있는 객체라는 것을 배웠다. 그러나 이렇게 수학 연산을 추적하는 과정이 w 값을 갱신하는 과정에서는 굳이 필요하지 않다. 따라서 첫번째 코드와 같이 텐서를 사용하면, 불필요한 수학 연산의 추적으로 인해 간접적인 연산 처리 시간인 오버헤드(overhead)만 발생한다. 그러나 두번째 코드에서는 직접 텐서의 데이터를 업데이트함으로써, 불필요한 연산 그래프 추적을 피한다.\n",
        "\n",
        "둘째로 추가적인 메모리 공간을 필요로 하지 않는다. 연산자 '-='는 증강 업데이트(augmented update)를 실행하는 연산자이다. 이는 컴퓨터가 새로운 메모리 공간을 할당하여 배열의 값을 교체하는 대신, 사용하던 메모리 공간을 그대로 다시 덮어쓰는 것을 의미한다. 따라서 기존 메모리 공간을 그대로 사용하므로, 메모리 사용이 최적화된다.\n",
        "\n",
        "조만간 신경망에 대해 배운 후, 어렵고 복잡한 수학적 함수의 파라미터를 조정하게 되면, 수많은 대규모 데이터를 업데이트하게 될 것이다. 이런 상황에서 위의 두가지 이점은 학습의 성능에 큰 차이를 만들 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "606ef82a",
      "metadata": {
        "id": "606ef82a"
      },
      "source": [
        "#### 경사하강법 코드 수정하기 (2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf2419b9",
      "metadata": {
        "id": "cf2419b9"
      },
      "source": [
        "이번에는 앞선 예제에서 다룬적 있는 이변수 함수 $\\mathscr{L}(w_1, w_2) = 2w_1^2 + 3w_2^2$에 대한 경사하강법을 수행하며 자동미분을 잘 활용해보자.\n",
        "\n",
        "앞선 예제에서는 $\\mathscr{L}(w) = w^2$의 도함수가 $\\frac{d \\mathscr{L}}{d w} = 2w$임을 알고 있는 상태에서 경사하강법 함수 descent_down_2d_parabola()를 작성해보았다.\n",
        "\n",
        "```python\n",
        "def descent_down_2d_parabola(w_start, learning_rate, num_steps):\n",
        "    xy_values = [w_start]\n",
        "    for _ in range(num_steps):\n",
        "        xy_old = xy_values[-1]\n",
        "        xy_new = xy_old - learning_rate * (np.array([4., 6.]) * xy_old)\n",
        "        xy_values.append(xy_new)\n",
        "    return np.array(xy_values)\n",
        "```\n",
        "\n",
        "이번에는 도함수를 모르는 $\\mathscr{L}(w_1, w_2)$에 대해서도 적용할 수 있는, 자동미분을 이용한 경사하강법 함수를 작성해보자. 다차원 텐서로 정의된 함수의 자동미분을 잘 떠올리면 해결하는 데 도움이 될 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0657ae3",
      "metadata": {
        "id": "f0657ae3"
      },
      "source": [
        "다음과 같이 $\\rm\\textbf w$의 시작점과 학습률 $\\delta$, 몇 단계 반복할 것인지가 주어졌다고 하자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8ff9d793",
      "metadata": {
        "id": "8ff9d793"
      },
      "outputs": [],
      "source": [
        "w = tc.tensor([2., 4.], requires_grad=True)\n",
        "learning_rate = 0.1\n",
        "num_steps = 30"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c03fd2c5",
      "metadata": {
        "id": "c03fd2c5"
      },
      "source": [
        "이러한 상황에 대해 아래의 코드를 채워 경사하강법을 수행하는 코드를 작성해보자. 제대로 코드를 작성한다면, 다음과 같이 $w_1=0, w_2=0$으로 서서히 가까워지는 결과가 출력될 것이다.\n",
        "```\n",
        "Tensor([1.2, 1.6])\n",
        "Tensor([0.72, 0.64])\n",
        "Tensor([0.432, 0.256])\n",
        "Tensor([0.2592, 0.1024])\n",
        "Tensor([0.15552, 0.04096])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "6dc9819f",
      "metadata": {
        "id": "6dc9819f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23e571fd-4adb-4da8-8129-fc6ad66e4832"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-2.1990e-07], requires_grad=True)\n",
            "tensor([4.3980e-07], requires_grad=True)\n",
            "tensor([-8.7961e-07], requires_grad=True)\n",
            "tensor([1.7592e-06], requires_grad=True)\n",
            "tensor([-3.5184e-06], requires_grad=True)\n",
            "tensor([7.0369e-06], requires_grad=True)\n",
            "tensor([-1.4074e-05], requires_grad=True)\n",
            "tensor([2.8147e-05], requires_grad=True)\n",
            "tensor([-5.6295e-05], requires_grad=True)\n",
            "tensor([0.0001], requires_grad=True)\n",
            "tensor([-0.0002], requires_grad=True)\n",
            "tensor([0.0005], requires_grad=True)\n",
            "tensor([-0.0009], requires_grad=True)\n",
            "tensor([0.0018], requires_grad=True)\n",
            "tensor([-0.0036], requires_grad=True)\n",
            "tensor([0.0072], requires_grad=True)\n",
            "tensor([-0.0144], requires_grad=True)\n",
            "tensor([0.0288], requires_grad=True)\n",
            "tensor([-0.0576], requires_grad=True)\n",
            "tensor([0.1153], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "const = tc.tensor([2.0, 3.0])\n",
        "for _ in range(num_steps):\n",
        "    ℒ = const * w ** 2\n",
        "    ℒ.sum().backward()\n",
        "    # 여기에 코드 작성\n",
        "\n",
        "    # w 업데이트 (메모리 최적화)\n",
        "    with tc.no_grad():\n",
        "        w -= learning_rate * w.grad\n",
        "\n",
        "    # w 값 출력\n",
        "    print(w)\n",
        "\n",
        "    # 그래디언트 초기화\n",
        "    w.grad.zero_()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f86fbb1",
      "metadata": {
        "id": "8f86fbb1"
      },
      "source": [
        "#### 일반적인 경사하강법 함수 작성하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "633555d6",
      "metadata": {
        "id": "633555d6"
      },
      "source": [
        "일변수 함수, 다변수 함수에 대해 경사하강법을 수행해보았으니, 보편적인 상황에 대해 적용할 수 있는 일반적인 경사하강법 함수를 작성하는 것만 남았다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78175514",
      "metadata": {
        "id": "78175514"
      },
      "source": [
        "<문제: 일반적인 경사하강법 함수 작성하기>\n",
        "\n",
        "이 문제의 목표는 어떤 함수가 어떤 텐서로 정의되어 있는지에 상관없이 사용할 수 있는 경사하강법 함수를 작성하는 것이다. 함수 외부에서 텐서와 텐서들로 정의된 함수를 모두 정의한 후, .backward() 메서드까지 실행한다. 함수 내부로는 텐서들만 전달해주어, 함수 내에서는 그 텐서들을 이용하여 경사하강법을 실행한다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d8ac2fb",
      "metadata": {
        "id": "4d8ac2fb"
      },
      "source": [
        "아래 함수의 주석을 잘 보고, 일반적인 경사하강법 함수를 작성해보자. 주석을 보면 이 함수는 단일 텐서를 인자로 입력받을 수도 있지만, 여러개의 텐서로 이루어진 iterable한 객체를 입력받을 수도 있다. 어떻게 코딩해야 할지 막막한 느낌이 든다면, 다음 힌트를 살펴보자.\n",
        "\n",
        "> HINT\n",
        "> 1. 여러 개의 텐서로 이루어진 iterable한 자료형이 들어올 수 있으므로, for문을 이용하여 텐서를 하나씩 꺼내며 경사하강하는 코드를 작성해야한다.\n",
        "> 2. 단일 텐서가 들어오면 for문을 이용할 수 없으므로, 단일 텐서를 단일 텐서가 들어있는 리스트로 바꾸어주는 과정이 있어야 한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "db9666b8",
      "metadata": {
        "id": "db9666b8"
      },
      "outputs": [],
      "source": [
        "def gradient_step(tensors, learning_rate):\n",
        "    \"\"\"\n",
        "    경사하강법의 공식에 따라 gradient-step을 실행.\n",
        "\n",
        "    매개변수 (Parameters)\n",
        "    ----------\n",
        "    tensors : Union[Tensor, Iterable[Tensors]]\n",
        "        단일 텐서, 혹은 텐서로 이루어진 iterable(리스트, 튜플 등) 모두 가능\n",
        "        만약 특정 tensor에 대한 `tensor.grad`가 `None`인 경우, 업데이트를 건너 뜀\n",
        "\n",
        "    learning_rate : float\n",
        "        매 gradient-step에서의 학습률. 양수\n",
        "\n",
        "    참고\n",
        "    -----\n",
        "    함수에서 진행되는 모든 gradient-steps는 tensor 내에서 바로 반영되므로, 반환 값 없음\n",
        "    \"\"\"\n",
        "    # isinstance 함수를 이용하여 입력된 tensors가 단일 텐서인지, iterable인지 판단한다\n",
        "\n",
        "    if isinstance(tensors, tc.Tensor):\n",
        "        # Only one tensor was provided. Pack\n",
        "        # it into a list so it can be accessed via\n",
        "        # iteration\n",
        "        tensors = [tensors]\n",
        "\n",
        "\n",
        "    # for 문을 이용하여 tensors의 tensor를 하나씩 꺼내며 경사하강을 진행\n",
        "    for t in tensors:\n",
        "        if t.grad is not None:\n",
        "            t.data -= learning_rate * t.grad\n",
        "            t.grad.zero_()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63edb99a",
      "metadata": {
        "id": "63edb99a"
      },
      "source": [
        "앞서 수행했던 함수 $\\mathscr{L}(w) = w^2$에 대한 경사하강법을 다시 한번 실행해봄으로써 보편적인 경사하강법 함수가 우리가 원하는대로 동작하는지 확인해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbf280d6",
      "metadata": {
        "id": "fbf280d6"
      },
      "outputs": [],
      "source": [
        "w = tc.tensor(10.0, requires_grad=True)\n",
        "learning_rate = 0.3\n",
        "num_steps = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "9abee228",
      "metadata": {
        "id": "9abee228",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61005de0-b09d-478a-eb4e-7feb446fc6d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0461], requires_grad=True)\n",
            "tensor([0.0184], requires_grad=True)\n",
            "tensor([0.0074], requires_grad=True)\n",
            "tensor([0.0030], requires_grad=True)\n",
            "tensor([0.0012], requires_grad=True)\n",
            "tensor([0.0005], requires_grad=True)\n",
            "tensor([0.0002], requires_grad=True)\n",
            "tensor([7.5558e-05], requires_grad=True)\n",
            "tensor([3.0223e-05], requires_grad=True)\n",
            "tensor([1.2089e-05], requires_grad=True)\n",
            "tensor([4.8357e-06], requires_grad=True)\n",
            "tensor([1.9343e-06], requires_grad=True)\n",
            "tensor([7.7371e-07], requires_grad=True)\n",
            "tensor([3.0948e-07], requires_grad=True)\n",
            "tensor([1.2379e-07], requires_grad=True)\n",
            "tensor([4.9517e-08], requires_grad=True)\n",
            "tensor([1.9807e-08], requires_grad=True)\n",
            "tensor([7.9228e-09], requires_grad=True)\n",
            "tensor([3.1691e-09], requires_grad=True)\n",
            "tensor([1.2676e-09], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "for _ in range(num_steps):\n",
        "    ℒ = w ** 2\n",
        "    ℒ.backward()\n",
        "    gradient_step(w, learning_rate=learning_rate)\n",
        "    print(w)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99313c60",
      "metadata": {
        "id": "99313c60"
      },
      "source": [
        "### 배운 내용 되돌아보기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cecca3d9",
      "metadata": {
        "id": "cecca3d9"
      },
      "source": [
        "이번 실습에서는 자동미분을 도와주는 PyTorch 라이브러리의 사용법을 배우고 익혔다. PyTorch는 앞으로의 거의 모든 실습에서 사용되는 중요한 라이브러리이다.\n",
        "\n",
        "- Tensor를 생성하는 여러 가지 함수들을 사용해보았다. 원소를 직접 적어줄 수도 있고, 리스트, 튜플, NumPy의 ndarray 등으로부터 Tensor를 생성할 수도 있었다.\n",
        "\n",
        "- 기존에 생성된 Tensor의 행과 열을 자유자재로 바꾸거나 일부 행이나 열만 슬라이싱 해보았다.\n",
        "\n",
        "- PyTorch에서 제공하는 다양한 수학 연산 함수들을 사용해보았다. 그 과정에서 NumPy의 함수들과의 유사성을 확인하였다.\n",
        "\n",
        "- 선형대수 연산을 돕는 함수인 matmul()과 einsum()을 사용해보았다.\n",
        "\n",
        "- PyTorch에 딥러닝을 위한 특수 함수들이 다양하게 존재함을 알게 되었으나, 사용해보지는 않았다.\n",
        "\n",
        "- PyTorch 텐서 객체의 .backward() 메서드를 사용하여 자동미분을 실행하고, 텐서의 .grad 속성을 이용하여 편미분 계수를 구해보았다.\n",
        "\n",
        "- 경사하강을 반복하며 최적의 모델을 찾아갈 때, 경사하강이 1회 종료될 때마다 기존의 편미분 계수를 폐기해주어야 함을 알게 되었다. 이를 위해 .grad 속성을 폐기하는 방법을 직접 사용해보았다.\n",
        "\n",
        "- PyTorch 텐서와 NumPy의 배열 사이의 관계를 알게 되었다.\n",
        "\n",
        "- 불필요한 편미분 계수를 계산하는 것을 방지하기 위해, 텐서를 상수 취급하는 방법을 도입해야 함을 알게 되었다. 그리고 텐서를 상수 취급하기 위한 방법을 사용해보았다.\n",
        "\n",
        "- 다차원 텐서에 대해 정의된 함수 (다변수 함수)에서 자동미분을 실행하면 다차원 텐서의 각 원소가 스칼라 값 변수로 해석되어 자동미분이 이루어짐을 알게 되었다. 또한 다차원 텐서의 .grad 속성에 함수의 그래디언트 값이 저장됨을 확인하였다.\n",
        "\n",
        "- 다변수 벡터 함수에 대해 자동미분을 실행하면 모든 성분함수를 합한 것에 대해 자동미분이 이루어짐을 알게 되었다. 또한 이런 규칙이 어떤 유용함을 가지는지 확인하였다.\n",
        "\n",
        "- PyTorch의 자동미분을 이용하여 경사하강법 함수를 새롭게 구현해보았다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "649f5f3b",
      "metadata": {
        "id": "649f5f3b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "3d1e928f",
        "61fa582a",
        "b10bbdab"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}